import * as dotenv from "dotenv";
dotenv.config();
import { TavilySearchResults } from "@langchain/community/tools/tavily_search";
import { Annotation } from "@langchain/langgraph";
import { createReactAgent } from "@langchain/langgraph/prebuilt";
import { ChatOpenAI } from "@langchain/openai";
import { planner } from "./plan";
import { END, START, StateGraph } from "@langchain/langgraph";
import { RunnableConfig } from "@langchain/core/runnables";
import { HumanMessage } from "@langchain/core/messages";
import { replanner } from "./replan";
import { execSummary } from "./summry";
import { baseLLMTool } from "../../langgrah_mcp/default-tool";

// âœ… å®šä¹‰æœç´¢å·¥å…·
const searchTool = new TavilySearchResults({
  maxResults: 3,
  apiKey: process.env.TAVILY_API_KEY,
});

// âœ… å®šä¹‰å·¥å…·åˆ—è¡¨
const tools = [searchTool, baseLLMTool];

// ğŸ¯ 2.1 å®šä¹‰çŠ¶æ€ï¼ˆStateï¼‰

const MAX_PLAN_COUNT = 3;

const PlanExecuteState = Annotation.Root({
  input: Annotation<string>({
    reducer: (x, y) => y ?? x ?? "",
  }),
  plan: Annotation<string[]>({
    reducer: (x, y) => y ?? x ?? [],
  }),
  pastSteps: Annotation<[string, string][]>({
    reducer: (x, y) => x.concat(y),
  }),
  response: Annotation<string>({
    reducer: (x, y) => y ?? x,
  }),
  // é¿å…ä¸€ç›´replanï¼Œæœ€å¤šreplan næ¬¡
  replanCount: Annotation<number>({
    reducer: (current, updated) => updated ?? current ?? 1,
    default: () => 1,
  }),
  // æ˜¯å¦å¯ä½¿ç”¨å†æ¬¡è®¡åˆ’
  canNotUseReplan: Annotation<boolean>({
    reducer: (current, updated) => updated ?? current ?? false,
    default: () => false,
  }),
});
export async function main() {
  const agentExecutor = createReactAgent({
    llm: new ChatOpenAI({ model: "gpt-4o" }),
    tools: tools,
  });

  async function planStep(
    state: typeof PlanExecuteState.State
  ): Promise<Partial<typeof PlanExecuteState.State>> {
    const plan = await planner.invoke({ objective: state.input });
    console.log("============å¼€å§‹ã€åˆ¶å®šã€‘è®¡åˆ’=======start========");
    console.log("input:", state, "\noutput:", plan.steps);
    return { plan: plan.steps };
  }
  async function executeStep(
    state: typeof PlanExecuteState.State,
    config?: RunnableConfig
  ): Promise<Partial<typeof PlanExecuteState.State>> {
    const task = state.plan[0];
    const input = {
      messages: [new HumanMessage(task)],
    };
    const { messages } = await agentExecutor.invoke(input, config);
    console.log("============å¼€å§‹ã€æ‰§è¡Œã€‘è®¡åˆ’=======start========");
    console.log("æ‰§è¡Œè®¡åˆ’åç§°: ", task);
    // console.log("input:", task, "\noutput:", messages);

    return {
      pastSteps: [[task, messages[messages.length - 1].content.toString()]],
      plan: state.plan.slice(1),
    };
  }

  async function summaryResult(state: typeof PlanExecuteState.State) {
    console.log("============å¼€å§‹ã€æ€»ç»“ã€‘ç»“æœ=======start========");
    console.log("\:pastSteps", state.pastSteps);
    const result = await execSummary({
      input: state.input,
      pastSteps: state.pastSteps
        .map(([step, result]) => `${step}: ${result}`)
        .join("\n"),
    });
    return {
      response: result,
    };
  }

  async function replanStep(
    state: typeof PlanExecuteState.State
  ): Promise<Partial<typeof PlanExecuteState.State>> {
    if (state.replanCount >= MAX_PLAN_COUNT) {
      return {
        response:
          "å·²ç»é‡æ–°è®¡åˆ’æ¬¡æ•°å·²è¾¾åˆ°ä¸Šçº¿ï¼Œæ— éœ€å†é‡æ–°è®¡åˆ’ï¼Œå¯ç›´æ¥æ‰§è¡Œä¸‹ä¸€æ­¥éª¤",
        canNotUseReplan: true,
      };
    }
    const output = await replanner.invoke({
      input: state.input,
      plan: state.plan.join("\n"),
      pastSteps: state.pastSteps
        .map(([step, result]) => `${step}: ${result}`)
        .join("\n"),
      replanCount: state.replanCount,
      maxReplanLimit: MAX_PLAN_COUNT,
    });

    console.log(
      "============é‡æ–°ã€åˆ¶å®šã€‘è®¡åˆ’ ç¬¬" +
        state.replanCount +
        "æ¬¡=======start========"
    );
    const toolCall = output?.[0];
    // console.log("input:", state, "\noutput:", toolCall.args);

    if (toolCall?.type == "response") {
      return {
        response: toolCall.args?.response,
        replanCount: state.replanCount + 1,
      };
    }
    console.log("é‡æ–°è®¡åˆ’åç§°: ", toolCall.args?.steps);

    return { plan: toolCall.args?.steps, replanCount: state.replanCount + 1 };
  }

  function shouldReplan(state: typeof PlanExecuteState.State) {
    if (state.plan.length === 0) {
      return "summary";
    }
    if (state?.canNotUseReplan) {
      return "next_task";
    }
    return "replan";
  }

  const workflow = new StateGraph(PlanExecuteState)
    .addNode("planner", planStep)
    .addNode("execute", executeStep)
    .addNode("replan", replanStep)
    .addNode("summary", summaryResult)
    .addEdge(START, "planner")
    .addEdge("planner", "execute")
    .addEdge("summary", END)
    .addConditionalEdges("execute", shouldReplan, {
      // é‡æ–°æ‰§è¡Œè®¡åˆ’
      replan: "replan",
      // ç»§ç»­æ‰§è¡Œä¸‹ä¸€ä¸ªè®¡åˆ’ï¼ˆå¤§æ¦‚ç‡æ˜¯replanè¶…è¿‡æ¬¡æ•°ï¼‰
      next_task: "execute",
      // ç»“æŸ
      summary: "summary",
    })
    .addEdge("replan", "execute");

  // Finally, we compile it!
  // This compiles it into a LangChain Runnable,
  // meaning you can use it as you would any other runnable
  const graph = workflow.compile();
  // è·å– graph
  const graphStructure = await graph.getGraphAsync();
  // ç»˜åˆ¶ mermaid å›¾
  const mermaid = graphStructure.drawMermaid();
  console.log("==================mermaid==================");
  console.log(mermaid);
  console.log("====================================");

  const config = { recursionLimit: 50 };
  const inputs = {
    input: "2024å¹´å­—èŠ‚è·³åŠ¨å‘å¸ƒçš„AIäº§å“æœ‰å“ªäº›? ä½¿ç”¨ä¸­æ–‡å›ç­”,å¹¶åˆ—ä¸¾å¯¹åº”çš„äº§å“è®¿é—®é“¾æ¥",
  };

  for await (const event of await graph.stream(inputs, config)) {
    console.log("result:", event);
  }
  ``;
}
